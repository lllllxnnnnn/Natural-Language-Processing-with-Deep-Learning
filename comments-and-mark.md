In this report, “Comprehend Sentiments in Product Reviews (Natural Language Processing with Deep Learning)”, it is proposed the implementation and evaluation of NLP and neural network models to predict sentiment labels for product reviews.

The Introduction section brings a good introduction to the context of the work (sentiment analysis) and its importance to customer-centred systems. There is a short but concise discussion, supported by examples, on how the scarcity of labeled data poses challenges for predicting the sentiment of a text (written) review. The main goal and research questions are presented. It would be nice to provide a summary of the main findings and contributions as well.

The solution concept is based on a logistic regression model acting as baseline for comparison. Then, an RNN model is deployed and tested against unstructured text reviews. Finally, an LSTM-based model is used to perform text labelling. All models are assessed through standard metrics. There is a detailed section explaining the feature pipeline applied to classify the data into 'negative' and 'positive' sentiments, and this is one positive point from the methodology. There is also a good explanation on the baseline model (logistic regression) and the proposed models (RNN and LSTM) and their resources for word/sequence processing (embeddings, tokenisation, and output function). The evaluation metrics and observed results are presented, with the LSTM model presenting a better performance (around 93%) compared to the other models (49% for the logistic regressor and 91% for RNN). Overall, the solution concept is fine and the methodology brings quite interesting results. It would be nice to clearly state specific contributions from this work (model definition and modelling, key aspects for training, and data manipulation), especially in terms of the state-of-the-art and existing models - eg which methodological decisions were taken to differentiate the proposed approach from existing ones?

The implementation involved feature engineering and building RNNs using Keras. The code is easy to read and has a good structure. It is well-commented.

The data used in this work comes from the Amazon Fine Food reviews, containing around 560,000 reviews written by approximately 256,000 users. The data structure containing numerical and non-numerical features is presented. Some data preprocessing and feature engineering tasks are described. Overall, the dataset is suitable for the proposed work. It would be nice to comment on the use of other datasets and how the proposed model would expect to perform in this case.

The numerical evaluation involved comparing the performance of the two models, as well as a baseline logistic model. Standard metrics are used and train-test accuracy are plotted. The author concludes that LSTM-based model outperforms the rest. Important feature works are identified such as hyper-parameter tuning.

The Conclusion section summarizes the methodological steps applied for experimenting with different neural network models targeting the proposed problem. The behaviour of the proposed models is discussed, based on internal characteristics of each model that could have been influenced the results. Some ideas for future work are discussed, including experimenting with other types of RNN models and ensemble of CNN and RNN models.

The presentation quality is good with substantial use of figures and tables. All the methodological steps are clearly described and well-documented. There is a good set of references that were properly used to support the results. One positive point is the paper-like structure adopted in the report.

Overall, this is quite an interesting work addressing a challenging application. The methodology is correctly applied to the research questions, resulting in a consistent code with substantial contributions and room for improvement. It would be nice to highlight specific contributions from the work and how they differ from existing models. There is a good set of ideas for future work, and I would recommend investing in them, especially the combined use of CNN and RNN models.

**Mark: 85**

